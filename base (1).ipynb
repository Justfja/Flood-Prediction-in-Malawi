{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics\n",
    "from shapely.geometry import Point,Polygon\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import shapely.wkt\n",
    "import shapely\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/raw_data/Train.csv')\n",
    "submission = pd.read_csv('../data/raw_data/SampleSubmission.csv')\n",
    "areas = pd.read_csv('../data/raw_data/protected_areas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'target_2015', 'elevation', 'precip 2014-11-16 - 2014-11-23',\n",
       "       'precip 2014-11-23 - 2014-11-30', 'precip 2014-11-30 - 2014-12-07',\n",
       "       'precip 2014-12-07 - 2014-12-14', 'precip 2014-12-14 - 2014-12-21',\n",
       "       'precip 2014-12-21 - 2014-12-28', 'precip 2014-12-28 - 2015-01-04',\n",
       "       'precip 2015-01-04 - 2015-01-11', 'precip 2015-01-11 - 2015-01-18',\n",
       "       'precip 2015-01-18 - 2015-01-25', 'precip 2015-01-25 - 2015-02-01',\n",
       "       'precip 2015-02-01 - 2015-02-08', 'precip 2015-02-08 - 2015-02-15',\n",
       "       'precip 2015-02-15 - 2015-02-22', 'precip 2015-02-22 - 2015-03-01',\n",
       "       'precip 2015-03-01 - 2015-03-08', 'precip 2015-03-08 - 2015-03-15',\n",
       "       'precip 2019-01-20 - 2019-01-27', 'precip 2019-01-27 - 2019-02-03',\n",
       "       'precip 2019-02-03 - 2019-02-10', 'precip 2019-02-10 - 2019-02-17',\n",
       "       'precip 2019-02-17 - 2019-02-24', 'precip 2019-02-24 - 2019-03-03',\n",
       "       'precip 2019-03-03 - 2019-03-10', 'precip 2019-03-10 - 2019-03-17',\n",
       "       'precip 2019-03-17 - 2019-03-24', 'precip 2019-03-24 - 2019-03-31',\n",
       "       'precip 2019-03-31 - 2019-04-07', 'precip 2019-04-07 - 2019-04-14',\n",
       "       'precip 2019-04-14 - 2019-04-21', 'precip 2019-04-21 - 2019-04-28',\n",
       "       'precip 2019-04-28 - 2019-05-05', 'precip 2019-05-05 - 2019-05-12',\n",
       "       'precip 2019-05-12 - 2019-05-19', 'LC_Type1_mode', 'Square_ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for area_index in range(len(areas)):\n",
    "    poly = []\n",
    "    for multipoly in shapely.wkt.loads(str(areas.iloc[area_index]['the_geom'])):\n",
    "      multi_poly_point = multipoly.centroid\n",
    "      poly.append((multi_poly_point.xy[0],multi_poly_point.xy[1]))\n",
    "    point = Point(poly[0][0][0],poly[0][1][0])\n",
    "    areas.loc[areas.index==area_index,'X'] = point.x\n",
    "    areas.loc[areas.index==area_index,'Y'] = point.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = areas.groupby('DISTRICT').mean()[['HOUSEHOLDS','MALE','FEMALE',\"AREA\",\"X\",\"Y\"]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_points = train[['X','Y']].apply(lambda x:(x['X'],x['Y']),1).tolist()\n",
    "areas_points = areas[['X','Y']].apply(lambda x:(x['X'],x['Y']),1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas.drop(['X','Y'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['areasindex'] = np.argmin(cdist(train_points,areas_points),1)\n",
    "train = train.merge(areas,how=\"left\",left_on=\"areasindex\",right_on=areas.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['areasindex'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.merge(drought_risk,how=\"left\",on=['X','Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x,y):\n",
    "  return np.sqrt(mean_squared_error(x,y))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.HOUSEHOLDS.fillna(train.HOUSEHOLDS.mean(),inplace=True)\n",
    "train.MALE.fillna(train.MALE.mean(),inplace=True)\n",
    "train.FEMALE.fillna(train.FEMALE.mean(),inplace=True)\n",
    "train.AREA.fillna(train.AREA.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train.groupby('LC_Type1_mode').mean()\n",
    "train_std  = train.groupby('LC_Type1_mode').std()\n",
    "train_mean_columns = list(train_mean.columns)\n",
    "train_std_columns = list(train_std.columns)\n",
    "for i in range(len(train_mean_columns)):\n",
    "    train_mean_columns[i] = train_mean_columns[i]+'MEAN'\n",
    "train_mean.columns = train_mean_columns\n",
    "train = train.merge(train_mean,how=\"left\",on=\"LC_Type1_mode\")\n",
    "\n",
    "\n",
    "for i in range(len(train_std_columns)):\n",
    "    train_std_columns[i] = train_std_columns[i]+'STD'\n",
    "train_std.columns = train_std_columns\n",
    "train = train.merge(train_std,how=\"left\",on=\"LC_Type1_mode\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'target_2015', 'elevation', 'precip 2014-11-16 - 2014-11-23',\n",
       "       'precip 2014-11-23 - 2014-11-30', 'precip 2014-11-30 - 2014-12-07',\n",
       "       'precip 2014-12-07 - 2014-12-14', 'precip 2014-12-14 - 2014-12-21',\n",
       "       'precip 2014-12-21 - 2014-12-28',\n",
       "       ...\n",
       "       'precip 2019-04-07 - 2019-04-14STD',\n",
       "       'precip 2019-04-14 - 2019-04-21STD',\n",
       "       'precip 2019-04-21 - 2019-04-28STD',\n",
       "       'precip 2019-04-28 - 2019-05-05STD',\n",
       "       'precip 2019-05-05 - 2019-05-12STD',\n",
       "       'precip 2019-05-12 - 2019-05-19STD', 'HOUSEHOLDSSTD', 'MALESTD',\n",
       "       'FEMALESTD', 'AREASTD'],\n",
       "      dtype='object', length=129)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = np.vstack((train[['Y','X']].values))\n",
    "indexes = np.arange(start=0, stop=len(coordinates), step=1)\n",
    "mbkmeans = MiniBatchKMeans(n_clusters=10, batch_size=500,random_state=42).fit(coordinates[indexes])\n",
    "train.loc[:, 'ClusterID'] = mbkmeans.predict(train[['Y', 'X']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['DISTRICT']:\n",
    "    \n",
    "    train[i] = train[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train.target_2015\n",
    "train_restricted = train.iloc[:12000].copy()\n",
    "target_restricted = target.iloc[:12000].copy()\n",
    "train.drop(['target_2015'],axis=1,inplace=True)\n",
    "train.drop(['Square_ID',\"LC_Type1_mode\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rest= train.iloc[12000:]\n",
    "target_rest = target.iloc[12000:]\n",
    "train_rest=train_rest[target_rest<0.1]\n",
    "target_rest=target_rest[target_rest<0.1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_pred=pd.read_csv(\"../outputs/oof/train/\"+\"lgbm_0.0728_Kfold\")\n",
    "# train_pred[\"ame\"]=(train_pred.target_2015-train_pred.target).abs()\n",
    "# id_to_remove=train_pred[(train_pred.target_2015>0.9)&(train_pred.ame<0.04)].Square_ID\n",
    "# len(id_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_restricted=pd.concat([train_restricted,train_rest])\n",
    "target_restricted=pd.concat([target_restricted,target_rest])\n",
    "train_restricted.target_2015=target_restricted.values\n",
    "train_restricted=train_restricted[~train_restricted.Square_ID.isin(id_to_remove)]\n",
    "target_restricted=train_restricted.target_2015\n",
    "target_restricted.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_restricted.drop(['target_2015'],axis=1,inplace=True)\n",
    "train_restricted.drop(['Square_ID',\"LC_Type1_mode\"],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's rmse: 0.0863084\tvalid_0's l2: 0.00744913\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's rmse: 0.0527329\tvalid_0's l2: 0.00278076\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's rmse: 0.0832981\tvalid_0's l2: 0.00693857\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's rmse: 0.154911\tvalid_0's l2: 0.0239973\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[228]\tvalid_0's rmse: 0.182613\tvalid_0's l2: 0.0333477\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's rmse: 0.124025\tvalid_0's l2: 0.0153822\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[405]\tvalid_0's rmse: 0.0621042\tvalid_0's l2: 0.00385694\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[494]\tvalid_0's rmse: 0.050538\tvalid_0's l2: 0.00255409\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[344]\tvalid_0's rmse: 0.0121346\tvalid_0's l2: 0.000147249\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's rmse: 0.0124803\tvalid_0's l2: 0.000155757\n",
      "CV score is =0.08211454775180267\n"
     ]
    }
   ],
   "source": [
    "Lightgbm = lgb.LGBMRegressor(n_estimators=100_000,random_state=1994,max_depth=8,learning_rate=0.02)\n",
    "Kfolds = KFold(n_splits=10,shuffle=False)\n",
    "test_prediction = np.zeros(len(train))\n",
    "cv_score = []\n",
    "for (train_index,test_index) in Kfolds.split(train_restricted,target_restricted):\n",
    "  X_train,X_test = train_restricted.iloc[train_index],train_restricted.iloc[test_index]\n",
    "  y_train,y_test = target_restricted.iloc[train_index],target_restricted.iloc[test_index]\n",
    "  Lightgbm.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=50,eval_metric='rmse',verbose=-1)  \n",
    "\n",
    "\n",
    "  test_pred = Lightgbm.predict(train)\n",
    "  validation_pred= Lightgbm.predict(X_test)\n",
    "\n",
    "\n",
    "  cv_score.append(rmse(validation_pred,y_test))\n",
    "\n",
    " \n",
    "  test_prediction+=test_pred\n",
    "    \n",
    "    \n",
    "print(\"CV score is ={}\".format(np.mean(cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import warnings\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# # sorted(zip(clf.feature_importances_, X.columns), reverse=True)\n",
    "# feature_imp = pd.DataFrame(sorted(zip(Lightgbm.feature_importances_,train.columns),reverse=True), columns=['Value','Feature'])\n",
    "\n",
    "# plt.figure(figsize=(30, 20))\n",
    "# sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "# plt.title('LightGBM Features (avg over folds)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14387,   328,   265,   183,   149,   136,   117,   125,   134,\n",
       "          642]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=pd.read_csv(\"xgbosot_kfold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_clipped=np.maximum(test_prediction/10,0)\n",
    "# test_pred_clipped=np.minimum(test_pred,1)\n",
    "submission['target_2019'] = ((np.absolute(test_prediction/10)))*0.6+kfold.target_2019*0.4\n",
    "# submission['target_2019'] = test_pred_clipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target_2019'] = submission['target_2019']*0.94\n",
    "\n",
    "# ((np.absolute(test_prediction/10)))*0.8\n",
    "submission.to_csv('lgbm_0.074_92.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[submission['target_2019']<=0.009,\"target_2019\"]=0.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lgbm_94_9.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    5513\n",
       "0.014511     255\n",
       "0.015056      96\n",
       "0.015080      66\n",
       "0.014497      57\n",
       "            ... \n",
       "0.025590       1\n",
       "0.048392       1\n",
       "0.052224       1\n",
       "0.009634       1\n",
       "0.221865       1\n",
       "Name: target_2019, Length: 7941, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.target_2019.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168.80938882138202"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['target_2015']=target\n",
    "submission[submission[\"target_2015\"]==0].target_2019.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.40469441069101\n"
     ]
    }
   ],
   "source": [
    "submission.loc[submission[\"target_2015\"]==0,\"target_2019\"]*=0.5  # try 0.4 \n",
    "print(submission[submission[\"target_2015\"]==0].target_2019.sum())\n",
    "del submission['target_2015']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lgbm_94_9_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
