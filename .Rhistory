prediction_type = "Probability")
p = p + pred
}
}
m = p/5
sub = cbind(test.id,m)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/sub4.csv"),row.names = F)
cat = m
dtrain = xgb.DMatrix(as.matrix(df_train[,feature2]), label=label2)
dtest = xgb.DMatrix(as.matrix(df_test[,feature2]))
param = list(booster = "gbtree",
objective = "binary:logistic",#"reg:gamma",
eval_metric = "logloss",
eta = 0.01,
colsample_bytree = 1,
max_depth = 4,
min_child_weight = 1,
#scale_pos_weight = 0.9,
#num_parallel_tree = 2,
nthread = 8,
#   base_score = mean(label),
gamma = 0,
subsample = 0.8
)
set.seed(1235)
mod.xgb = xgb.train(data = dtrain,params = param,nrounds = 1000)
imp = as.data.frame(xgb.importance(feature_names = colnames(df_train),model = mod.xgb))
pred= predict(mod.xgb,dtest)
xgb2 = pred
sub = cbind(test.id,xgb2)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/sub4.csv"),row.names = F)
# folds = createFolds(as.factor(label),k = 5)
devresult = rep(0,nrow(df_train))
p = rep(0, nrow(df_test))
dtest = catboost.load_pool(as.matrix(df_test[,colnames(df_train)]))
# set.seed(501)
# folds = createFolds(as.factor(label),k = 5)
devresult = rep(0,nrow(df_train))
p = rep(0, nrow(df_test))
dtest = catboost.load_pool(as.matrix(df_test[,colnames(df_train)]))
### create a matrix for predictions
#pred_te <- rep(0, nrow(df_test))
for (i in 1) {
print(paste0("model training on label ", i))
#label = cv_label[,i]
for(rnd in 1:length(folds)){
valid = c(1:length(label))[unlist(folds[rnd])]
dev = c(1:length(label))[unlist(folds[1:length(folds) != rnd])]
dtrain = catboost.load_pool(as.matrix(df_train[dev,]), label=label2[dev])
dvalid = catboost.load_pool(as.matrix(df_train[valid,]),label=label2[valid])
params = list(
iterations = 5000,
learning_rate = 0.01,
depth = 3,
eval_metric = "Logloss",
loss_function = "Logloss",
random_seed = 1235,
use_best_model = TRUE,
logging_level = "Verbose",
rsm = 1,
od_type = "Iter",
od_wait = 50,
metric_period = 2000
)
# set.seed(1235)
model = catboost.train(learn_pool = dtrain,test_pool = dvalid,
params = params)
predt = catboost.predict(model,
pool = catboost.load_pool(as.matrix(df_train[valid,])),
prediction_type = "Probability")
devresult[valid] = predt
pred = catboost.predict(model, pool = dtest,
prediction_type = "Probability")
p = p + pred
}
}
m = p/5
sub = cbind(test.id,m)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/sub4.csv"),row.names = F)
cor(cat,m)
colnames(df)
feature3 = colnames(df[,1:32])
devresult = rep(0,nrow(df_train))
p = rep(0, nrow(df_test))
dtest = catboost.load_pool(as.matrix(df_test[,feature3]))
#pred_te <- rep(0, nrow(df_test))
for (i in 1) {
print(paste0("model training on label ", i))
#label = cv_label[,i]
for(rnd in 1:length(folds)){
valid = c(1:length(label))[unlist(folds[rnd])]
dev = c(1:length(label))[unlist(folds[1:length(folds) != rnd])]
dtrain = catboost.load_pool(as.matrix(df_train[dev,feature3]), label=label2[dev])
dvalid = catboost.load_pool(as.matrix(df_train[valid,feature3]),label=label2[valid])
params = list(
iterations = 5000,
learning_rate = 0.01,
depth = 3,
eval_metric = "Logloss",
loss_function = "Logloss",
random_seed = 1235,
use_best_model = TRUE,
logging_level = "Verbose",
rsm = 1,
od_type = "Iter",
od_wait = 50,
metric_period = 2000
)
# set.seed(1235)
model = catboost.train(learn_pool = dtrain,test_pool = dvalid,
params = params)
predt = catboost.predict(model,
pool = catboost.load_pool(as.matrix(df_train[valid,feature3])),
prediction_type = "Probability")
devresult[valid] = predt
pred = catboost.predict(model, pool = dtest,
prediction_type = "Probability")
p = p + pred
}
}
m = p/5
sub = cbind(test.id,m)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/sub4.csv"),row.names = F)
cor(cat,m)
m = 0.7*cat+0.3*xgb2
sub = cbind(test.id,m)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/sub4.csv"),row.names = F)
regression_feat
df_train = cbind(df_train,label)
df_train = df_train[1:12000,]
label3 = df_train$label
df_train$label = NULL
devresult = rep(0,nrow(df_train))
predte = rep(0,nrow(df_test))
cvscore = c()
int.seed = c(500)
for (i in 1:length(int.seed)) {
cat("model training",i,"\n")
set.seed(int.seed[i])
folds = createFolds(label3, k = 5)
param = list(objective = "regression_l2",
metric = "rmse",
#boost_from_average = "false",
#tree_learner = "serial",
feature_fraction = 0.5,
bagging_freq = 1,
bagging_fraction = 0.8
#lambda = 1,
#alpha = 1
# max_bin = 63
# min_data_in_leaf = 90,
# min_sum_hessian_in_leaf = 10
#min_split_gain = 0.1,
)
for (this.round in 1:length(folds)) {
cat("model training",i," ","fold ",this.round,"\n")
valid = c(1:length(label3))[unlist(folds[this.round])]
dev = c(1:length(label3))[unlist(folds[1:length(folds)!= this.round])]
dtrain = lgb.Dataset(data = as.matrix(df_train[dev,regression_feat]),
label = label3[dev], free_raw_data = F)
dvalid = lgb.Dataset(data = as.matrix(df_train[valid,regression_feat]),
label = label3[valid],free_raw_data= F)
model = lgb.train(data = dtrain,
params = param,
nrounds = 1000,
valids = list(val1 = dvalid, val2 = dtrain),
boosting_type = "gbdt",
learning_rate = 0.01,
max_depth = -1,
num_leaves = 13,
num_threads = 4,
eval_freq = 500,
seed = 1235,
verbose = 1,
early_stopping_rounds = 20
)
pred = predict(model,as.matrix(df_train[valid,regression_feat]))
devresult[valid] = pred
pred_test = predict(model, as.matrix(df_test[,regression_feat]))
predte = predte + pred_test
cat("model cv rmse score:", model$best_score,"\n")
cvscore = c(cvscore, model$best_score)
cat("model cv rmse mean score:",mean(cvscore), "\n")
}
}
pred = predte/5
pred = ifelse(pred<0.1,0,pred)
m2 = 0.7*m+0.3*pred
sub = cbind(test.id,m2)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/sub4.csv"),row.names = F)
#m = cbind(xccsub2,label)
m = data.frame(id = sub[,1],target_2019 =m2,label =label)
m$rr = ifelse(m$label==1 & m$target_2019>0.6 &m$target_2019<0.9,1,0)#0.85
m$rr2 = ifelse(m$label <0.3 & m$target_2019>0.5,1,0)#0.8
m$rr4 = ifelse(m$label>0.85 &m$label< 1& m$target_2019>0.80 & m$target_2019<0.9,1,0)#0.8
m$rr5 = ifelse(m$label>0.85 &m$label< 1& m$target_2019>0.6 & m$target_2019<0.8,1,0)#0.8
#m$rr4 = ifelse(m$label>0.9&m$target_2019>0.4 & m$target_2019<0.5,1,0)
m$rr6 = ifelse(m$label>0.75 &m$label< 0.85 & m$target_2019>0.7 &m$target_2019<0.8,1,0)#0.8
m4 = ifelse(m$rr==1,0.8,m$target_2019)
m4 = ifelse(m$rr2==1,0.7,m4)
m4 = ifelse(m$rr4==1,0.75,m4)
m4 = ifelse(m$rr5==1,0.75,m4)
m4 = ifelse(m$rr6==1,0.9,m4)
sub = cbind(test.id,m4)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/sub4.csv"),row.names = F)
m4 = ifelse(m$rr==1,0.8,m$target_2019)
m4 = ifelse(m$rr2==1,0.7,m4)
m4 = ifelse(m$rr4==1,0.75,m4)
m4 = ifelse(m$rr5==1,0.75,m4)
sub = cbind(test.id,m4)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/sub4.csv"),row.names = F)
df_train = df[1:length(train.id),]
df_test = df[(length(train.id)+1):nrow(df),]
str(df_train)
df_train = df[1:length(train.id),]
df_test = df[(length(train.id)+1):nrow(df),]
dtrain = xgb.DMatrix(as.matrix(df_train[,feature2]), label=label2)
dtest = xgb.DMatrix(as.matrix(df_test[,feature2]))
param = list(booster = "gbtree",
objective = "binary:logistic",
eval_metric = "logloss",
eta = 0.01,
colsample_bytree = 1,
max_depth = 4,
min_child_weight = 1,
nthread = 4,
gamma = 0,
subsample = 0.8
)
set.seed(1235)
mod.xgb = xgb.train(data = dtrain,params = param,nrounds = 1000)
imp = as.data.frame(xgb.importance(feature_names = colnames(df_train),model = mod.xgb))
pred= predict(mod.xgb,dtest)
xgb_class = pred
sub = cbind(test.id,xgb_class)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/xgb_classifaction.csv"),row.names = F)
devresult = rep(0,nrow(df_train)) ## train oof
p = rep(0, nrow(df_test)) ### test prediction
dtest = catboost.load_pool(as.matrix(df_test[,feature1]))
set.seed(500)
folds = createFolds(as.factor(label),k = 5)
### SELECT FEATURES
feature1 = c(colnames(df[,1:26]),"msk_alt","LC_Type1_mode_X_cnt")
data1
feature1
### SELECT FEATURES
feature1 = c(colnames(df[,1:26]),"LC_Type1_mode_X_cnt","dist_to_shire")
feature1
devresult = rep(0,nrow(df_train)) ## train oof
p = rep(0, nrow(df_test)) ### test prediction
dtest = catboost.load_pool(as.matrix(df_test[,feature1]))
set.seed(500)
folds = createFolds(as.factor(label),k = 5)
for (i in 1) {
print(paste0("model training on label ", i))
for(rnd in 1:length(folds)){
valid = c(1:length(label))[unlist(folds[rnd])]
dev = c(1:length(label))[unlist(folds[1:length(folds) != rnd])]
dtrain = catboost.load_pool(as.matrix(df_train[dev,feature1]), label=label2[dev])
dvalid = catboost.load_pool(as.matrix(df_train[valid,feature1]),label=label2[valid])
params = list(
iterations = 5000,
learning_rate = 0.01,
depth = 3,
eval_metric = "Logloss",
loss_function = "Logloss",
random_seed = 1235,
use_best_model = TRUE,
logging_level = "Verbose",
rsm = 1,
od_type = "Iter",
od_wait = 50,
metric_period = 2000
)
model = catboost.train(learn_pool= dtrain,test_pool= dvalid,params = params)
predt = catboost.predict(model,
pool = catboost.load_pool(as.matrix(df_train[valid,feature1])),
prediction_type = "Probability")
devresult[valid] = predt
pred = catboost.predict(model, pool = dtest,
prediction_type = "Probability")
p = p + pred
}
}
pred= p/5
cat_class = pred
sub = cbind(test.id,cat_class)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/catboost_classifaction.csv"),row.names = F)
data1
feature1
setdiff(data1,feature1)
dim(d)
dim(df_train)
set.seed(int.seed[i])
folds = createFolds(label3, k = 5)
##### MODEL 2    CATBOOST
devresult = rep(0,nrow(df_train)) ## train oof
p = rep(0, nrow(df_test)) ### test prediction
dtest = catboost.load_pool(as.matrix(df_test[,feature1]))
for (i in 1) {
print(paste0("model training on label ", i))
for(rnd in 1:length(folds)){
valid = c(1:length(label))[unlist(folds[rnd])]
dev = c(1:length(label))[unlist(folds[1:length(folds) != rnd])]
dtrain = catboost.load_pool(as.matrix(df_train[dev,feature1]), label=label2[dev])
dvalid = catboost.load_pool(as.matrix(df_train[valid,feature1]),label=label2[valid])
params = list(
iterations = 5000,
learning_rate = 0.01,
depth = 3,
eval_metric = "Logloss",
loss_function = "Logloss",
random_seed = 1235,
use_best_model = TRUE,
logging_level = "Verbose",
rsm = 1,
od_type = "Iter",
od_wait = 50,
metric_period = 2000
)
model = catboost.train(learn_pool= dtrain,test_pool= dvalid,params = params)
predt = catboost.predict(model,
pool = catboost.load_pool(as.matrix(df_train[valid,feature1])),
prediction_type = "Probability")
devresult[valid] = predt
pred = catboost.predict(model, pool = dtest,
prediction_type = "Probability")
p = p + pred
}
}
m = p/5
sub = cbind(test.id,m)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/sub4.csv"),row.names = F)
df_train = cbind(df_train,label)
df_train = df_train[1:12000,]
label3 = df_train$label
df_train$label = NULL
devresult = rep(0,nrow(df_train))
predte = rep(0,nrow(df_test))
cvscore = c()
int.seed = c(500)
for (i in 1:length(int.seed)) {
cat("model training",i,"\n")
set.seed(int.seed[i])
folds = createFolds(label3, k = 5)
param = list(objective = "regression_l2",
metric = "rmse",
feature_fraction = 0.5,
bagging_freq = 1,
bagging_fraction = 0.8
)
for (this.round in 1:length(folds)) {
cat("model training",i," ","fold ",this.round,"\n")
valid = c(1:length(label3))[unlist(folds[this.round])]
dev = c(1:length(label3))[unlist(folds[1:length(folds)!= this.round])]
dtrain = lgb.Dataset(data = as.matrix(df_train[dev,regression_feat]),
label = label3[dev], free_raw_data = F)
dvalid = lgb.Dataset(data = as.matrix(df_train[valid,regression_feat]),
label = label3[valid],free_raw_data= F)
model = lgb.train(data = dtrain,
params = param,
nrounds = 1000,
valids = list(val1 = dvalid, val2 = dtrain),
boosting_type = "gbdt",
learning_rate = 0.01,
max_depth = -1,
num_leaves = 13,
num_threads = 4,
eval_freq = 500,
seed = 1235,
verbose = 1,
early_stopping_rounds = 20
)
pred = predict(model,as.matrix(df_train[valid,regression_feat]))
devresult[valid] = pred
pred_test = predict(model, as.matrix(df_test[,regression_feat]))
predte = predte + pred_test
cat("model cv rmse score:", model$best_score,"\n")
cvscore = c(cvscore, model$best_score)
cat("model cv rmse mean score:",mean(cvscore), "\n")
}
}
pred = predte/5
pred = ifelse(pred<0.1,0,pred)
lgb_reg = pred
sub = cbind(test.id,lgb_reg)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/lgb_regression.csv"),row.names = F)
##### FINAL ENSEMBLES AND PROCESSING
ensemble1 = 0.7*cat_class+ 0.3*xgb_class
final = 0.7*ensemble1 + 0.3*lgb_reg## 0.
sub = cbind(test.id,final)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/final.csv"),row.names = F)
devresult = rep(0,nrow(df_train)) ## train oof
p = rep(0, nrow(df_test)) ### test prediction
dtest = catboost.load_pool(as.matrix(df_test[,feature1]))
for (i in 1) {
print(paste0("model training on label ", i))
for(rnd in 1:length(folds)){
valid = c(1:length(label))[unlist(folds[rnd])]
dev = c(1:length(label))[unlist(folds[1:length(folds) != rnd])]
dtrain = catboost.load_pool(as.matrix(df_train[dev,feature1]), label=label2[dev])
dvalid = catboost.load_pool(as.matrix(df_train[valid,feature1]),label=label2[valid])
params = list(
iterations = 5000,
learning_rate = 0.01,
depth = 3,
eval_metric = "Logloss",
loss_function = "Logloss",
random_seed = 1235,
use_best_model = TRUE,
logging_level = "Verbose",
rsm = 1,
od_type = "Iter",
od_wait = 50,
metric_period = 2000
)
model = catboost.train(learn_pool= dtrain,test_pool= dvalid,params = params)
predt = catboost.predict(model,
pool = catboost.load_pool(as.matrix(df_train[valid,feature1])),
prediction_type = "Probability")
devresult[valid] = predt
pred = catboost.predict(model, pool = dtest,
prediction_type = "Probability")
p = p + pred
}
}
pred= p/5
cat_class = pred
sub = cbind(test.id,cat_class)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/catboost_classifaction.csv"),row.names = F)
##### FINAL ENSEMBLES AND PROCESSING
ensemble1 = 0.7*cat_class+ 0.3*xgb_class
final = 0.7*ensemble1 + 0.3*lgb_reg## 0.796
sub = cbind(test.id,final)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/final.csv"),row.names = F)
head(sub)
final = final*1.02
sub = cbind(test.id,final)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/final.csv"),row.names = F)
final = 0.7*ensemble1 + 0.3*lgb_reg
final = final*0.95
sub = cbind(test.id,final)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/final.csv"),row.names = F)
final = 0.7*ensemble1 + 0.3*lgb_reg
final = final*0.90
sub = cbind(test.id,final)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/final.csv"),row.names = F)
final = 0.7*ensemble1 + 0.3*lgb_reg
final = data.frame(id = sub[,1],target_2019 =final,label =label)
final$process1 = ifelse(final$label==1 & final$target_2019>0.6 &final$target_2019<0.9,1,0)
final$process2 = ifelse(final$label <0.3 & final$target_2019>0.5,1,0)
final = ifelse(final$process1==1,0.8,final$target_2019)
final = ifelse(final$process2==1,0.7,final)
final2 = ifelse(final$process2==1,0.7,final)
final = 0.7*ensemble1 + 0.3*lgb_reg
### FINAL PROCESSING
final = data.frame(id = sub[,1],target_2019 =final,label =label)
final$process1 = ifelse(final$label==1 & final$target_2019>0.6 &final$target_2019<0.9,1,0)
final$process2 = ifelse(final$label <0.3 & final$target_2019>0.5,1,0)
final = ifelse(final$process1==1,0.8,final$target_2019)
final2 = ifelse(final$process2==1,0.7,final)
### FINAL PROCESSING
final = data.frame(id = sub[,1],target_2019 =final,label =label)
final$process1 = ifelse(final$label==1 & final$target_2019>0.6 &final$target_2019<0.9,1,0)
final$process2 = ifelse(final$label <0.3 & final$target_2019>0.5,1,0)
final2 = ifelse(final$process1==1,0.8,final$target_2019)
final2 = ifelse(final$process2==1,0.7,final2)
sub = cbind(test.id,final2)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/final.csv"),row.names = F)
final2 = ifelse(final$process1==1,0.9,final$target_2019)
final2 = ifelse(final$process2==1,0.8,final2)
sub = cbind(test.id,final2)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/final.csv"),row.names = F)
final$process1 = ifelse(final$label>0.85 &final$label< 1& final$target_2019>0.80 & final$target_2019<0.9,1,0)#0.8
final$process2 = ifelse(final$label>0.85 &final$label< 1& final$target_2019>0.6 & final$target_2019<0.8,1,0)#0.8
final = 0.7*ensemble1 + 0.3*lgb_reg
### FINAL PROCESSING
final = data.frame(id = sub[,1],target_2019 =final,label =label)
final$process1 = ifelse(final$label>0.85 &final$label< 1& final$target_2019>0.80 & final$target_2019<0.9,1,0)#0.8
final$process2 = ifelse(final$label>0.85 &final$label< 1& final$target_2019>0.6 & final$target_2019<0.8,1,0)#0.8
final2 = ifelse(final$process1==1,0.75,final$target_2019)
final2 = ifelse(final$process2==1,0.75,final2)
sub = cbind(test.id,final2)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/final.csv"),row.names = F)
sub = cbind(test.id,final2)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/final2.csv"),row.names = F)
final = 0.7*ensemble1 + 0.3*lgb_reg
sub = cbind(test.id,final)
colnames(sub) = colnames(samp)
write.csv(sub,file = paste0(subm.dir,"/final.csv"),row.names = F)
